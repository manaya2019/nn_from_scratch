{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#je construis mon data set d'entrainement avec la methode xor\n",
    "X = np.random.randint(2, size = (2, 4)) #mon dataset est constitué de 2 exemples(0 et 1), sa taille est 2 lignes et 400 colonnes\n",
    "Y = np.logical_xor(X[0, :], X[1, :]) # Y est mon label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (2, 4)\n",
      "Y.shape =  (1, 4)\n"
     ]
    }
   ],
   "source": [
    "Y = Y.reshape(1, 4)\n",
    "print(\"X.shape = \", X.shape)\n",
    "print(\"Y.shape = \", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture de mon reseau de neurone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = [2, 3, 3, 1]\n",
    "def initialisation_param(architecture):\n",
    "    np.random.seed(1)\n",
    "    couches = len(architecture)# nombre de layers y compris le input layer. Or concretement, ce dernier ne fait pas parti de notre réseau de neurone\n",
    "    parametres = {}\n",
    "    \n",
    "    for l in range(1, couches):\n",
    "        parametres[\"W\" + str(l)] = np.random.randn(architecture[l],architecture[l-1])*0.01\n",
    "        parametres[\"b\" + str(l)] = np.zeros((architecture[l], 1))\n",
    "    \n",
    "    return parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.01624345, -0.00611756],\n",
       "        [-0.00528172, -0.01072969],\n",
       "        [ 0.00865408, -0.02301539]]), 'b1': array([[0.],\n",
       "        [0.],\n",
       "        [0.]]), 'W2': array([[ 0.01744812, -0.00761207,  0.00319039],\n",
       "        [-0.0024937 ,  0.01462108, -0.02060141],\n",
       "        [-0.00322417, -0.00384054,  0.01133769]]), 'b2': array([[0.],\n",
       "        [0.],\n",
       "        [0.]]), 'W3': array([[-0.01099891, -0.00172428, -0.00877858]]), 'b3': array([[0.]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametres = initialisation_param(architecture)\n",
    "parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01624345, -0.00611756],\n",
       "       [-0.00528172, -0.01072969],\n",
       "       [ 0.00865408, -0.02301539]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parametres[\"W\" + str(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    S = 1/(1+ np.exp(-z))\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parametres)\n",
    "len(architecture)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, parametres):\n",
    "    caches = {} #creation de dictionnaire vide pour stocker les resultats \n",
    "    caches[\"A0\"] = X #A0 = X\n",
    "    \n",
    "    param= len(parametres)//2  \n",
    "    \n",
    "    for i in range(1,param+1):\n",
    "        \n",
    "        A = caches[\"A\" + str(i - 1)] \n",
    "    \n",
    "        W = parametres[\"W\" + str(i)]\n",
    "        \n",
    "        b = parametres[\"b\" + str(i)]\n",
    "\n",
    "        Z = np.dot(W,A) + b\n",
    "\n",
    "        A = sigmoid(Z) #A1\n",
    "\n",
    "        caches[\"A\" + str(i)] = A #on enregistre A1 dans le dict\n",
    "\n",
    "#         Z1 = np.dot(W1, X)+b1\n",
    "#         A1 = sigmoid(Z1)\n",
    "#         Z2 = np.dot(W2, A1)+b2\n",
    "#         A2 = sigmoid(Z2)\n",
    "#         Z3 = np.dot(W3, A2)+b3\n",
    "#         A3 = sigmoid(Z3)\n",
    "\n",
    "    return A, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A0': array([[1, 0, 0, 0],\n",
       "        [1, 1, 1, 0]]),\n",
       " 'A1': array([[0.50253145, 0.49847061, 0.49847061, 0.5       ],\n",
       "        [0.49599723, 0.4973176 , 0.4973176 , 0.5       ],\n",
       "        [0.49640973, 0.49424641, 0.49424641, 0.5       ]]),\n",
       " 'A2': array([[0.5016441 , 0.50162214, 0.50162214, 0.5016283 ],\n",
       "        [0.49894303, 0.49896153, 0.49896153, 0.49894075],\n",
       "        [0.50052575, 0.50052162, 0.50052162, 0.50053412]]),\n",
       " 'A3': array([[0.49730708, 0.49730715, 0.49730715, 0.49730711]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, caches = forward(X, parametres)\n",
    "A\n",
    "caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(A, Y):\n",
    "    m = Y.shape[1]\n",
    "    L = np.multiply(np.log(A), Y)+(1-Y)* np.log(1-A)\n",
    "    cost = - np.sum(L)/4\n",
    "    \n",
    "    cost = np.squeeze(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931616355342991"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(A , Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [1, 1, 1, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caches['A0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(parametres, caches, Y ):\n",
    "    \"\"\"\n",
    "    Backward propagation sans boucle for.\n",
    "    :m = nombres d'exemples\n",
    "    \n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    #J'extrais les poids du dictionnaire parametres, en faisant appel aux clés associées\n",
    "    W1= parametres['W1']\n",
    "    W2= parametres['W2']\n",
    "    W3 = parametres['W3']\n",
    "    \n",
    "    #j'extrais A: activations de chaque neurone\n",
    "    A1 = caches['A1']\n",
    "    A2 = caches['A2']\n",
    "    A3 = caches['A3']\n",
    "    A0 = caches['A0']\n",
    "    \n",
    "    #calculs de dérivées pour la backward\n",
    "    dZ3 = A3 - Y\n",
    "    \n",
    "    dW3 = np.dot(dZ3, A2.T)\n",
    "    db3 = np.sum(dZ3, axis = 1, keepdims = True)/m \n",
    "    \n",
    "    dA2 = np.dot(W3.T,dZ3)     # derivée de l'activation A2\n",
    "    dZ2 = dA2 * A3 * (1 - A3)  # derivée de la sigmoid Z2\n",
    "    dW2 = np.dot(dZ2, A2.T)    # dérivée du poids w3\n",
    "    db2 = np.sum(dZ2, axis =1, keepdims = True)/m\n",
    "    \n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = dA1 * A2 * (1 - A2)\n",
    "    dW1 = np.dot(dZ1, A0.T)\n",
    "    db1 = np.sum(dZ1, axis =1, keepdims = True)/m\n",
    "    \n",
    "    grads = {\"dW1\" : dW1,\n",
    "            \"db1\" : db1,\n",
    "            \"dW2\" : dW2,\n",
    "            \"db2\" : db2,\n",
    "            \"dW3\": dW3,\n",
    "            \"db3\": db3}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pro(parametres, caches, Y):\n",
    "    \"\"\"\n",
    "    Utilisation de boucle for pour automatiser le code.\n",
    "    \"\"\"\n",
    "    \n",
    "    grads = {}\n",
    "    couches = len(parametres//2)\n",
    "    grads[\"dZ\"] = caches[\"A\" + str(couches)]-Y\n",
    "    \n",
    "    for i in reversed(range(couches+1)):\n",
    "        W = parametres[\"W\" + str(i)]\n",
    "        A = caches[\"A\" + str(i-1)]\n",
    "        dZ = grads [\"dZ\" + str(i)]\n",
    "        \n",
    "        #calculs dérivées\n",
    "        dA = np.dot(W.T,dZ)\n",
    "        dZ = dA * A * (1 - A)\n",
    "        dW = np.dot(dZ, A.T)\n",
    "        db = np.sum(dZ, axis =1, keepdims = True)/m\n",
    "        \n",
    "        grads[\"dW\" + str(i)] = dW\n",
    "        grads[\"dZ\" + str(i)] = dZ\n",
    "        grads[\"db\" + str(i)] = db\n",
    "       \n",
    "    \n",
    "        return grads\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dW1': array([[-4.95132810e-06,  5.05857542e-06],\n",
       "        [ 2.86651113e-06, -2.92859990e-06],\n",
       "        [-3.08001285e-06,  3.14672522e-06]]), 'db1': array([[ 2.68115103e-08],\n",
       "        [-1.55221686e-08],\n",
       "        [ 1.66780793e-08]]), 'dW2': array([[1.48185479e-05, 1.48318942e-05, 1.48016518e-05],\n",
       "        [2.32308022e-06, 2.32517250e-06, 2.32043146e-06],\n",
       "        [1.18271573e-05, 1.18378094e-05, 1.18136720e-05]]), 'db2': array([[7.40446874e-06],\n",
       "        [1.16078681e-06],\n",
       "        [5.90974345e-06]]), 'dW3': array([[-0.00538925, -0.00539411, -0.00538311]]), 'db3': array([[-0.00269288]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads = backward(parametres, caches, Y)\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parametres(parametres, grads, l_r=1.2):\n",
    "    \n",
    "    parametres[\"W1\"] = parametres[\"W1\"]-l_r * grads[\"dW1\"]\n",
    "    parametres[\"W2\"] = parametres[\"W2\"]-l_r * grads[\"dW2\"]\n",
    "    parametres[\"W3\"] = parametres[\"W3\"]-l_r * grads[\"dW3\"]\n",
    "    parametres[\"b1\"] = parametres[\"b1\"]-l_r * grads[\"db1\"]\n",
    "    parametres[\"b2\"] = parametres[\"b2\"]-l_r * grads[\"db2\"]\n",
    "    parametres[\"b3\"] = parametres[\"b3\"]-l_r * grads[\"db3\"]\n",
    "    \n",
    "    return parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.0162494 , -0.00612363],\n",
       "        [-0.00528516, -0.01072617],\n",
       "        [ 0.00865777, -0.02301916]]), 'b1': array([[-3.21738123e-08],\n",
       "        [ 1.86266024e-08],\n",
       "        [-2.00136951e-08]]), 'W2': array([[ 0.01743034, -0.00762987,  0.00317263],\n",
       "        [-0.00249649,  0.01461829, -0.02060419],\n",
       "        [-0.00323836, -0.00385475,  0.01132352]]), 'b2': array([[-8.88536249e-06],\n",
       "        [-1.39294417e-06],\n",
       "        [-7.09169214e-06]]), 'W3': array([[-0.00453181,  0.00474864, -0.00231886]]), 'b3': array([[0.00323145]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_parametres(parametres, grads, l_r=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_p_with_for(parametres, grads, learning_rate = 1.2):\n",
    "\n",
    "    param = len(parametres)//2\n",
    "    \n",
    "    for p in range(param):\n",
    "        parametres[\"W\" + str(p+1)] = parametres[\"W\" + str(p+1)] -learning_rate * grads[\"dW\" + str(p+1)]\n",
    "        parametres[\"b\" + str(p+1)] = parametres[\"b\" + str(p+1)] - learning_rate * grads[\"db\"+ str(p+1)]\n",
    "        \n",
    "        return parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.01625534, -0.0061297 ],\n",
       "        [-0.0052886 , -0.01072266],\n",
       "        [ 0.00866147, -0.02302294]]), 'b1': array([[-6.43476247e-08],\n",
       "        [ 3.72532047e-08],\n",
       "        [-4.00273903e-08]]), 'W2': array([[ 0.01743034, -0.00762987,  0.00317263],\n",
       "        [-0.00249649,  0.01461829, -0.02060419],\n",
       "        [-0.00323836, -0.00385475,  0.01132352]]), 'b2': array([[-8.88536249e-06],\n",
       "        [-1.39294417e-06],\n",
       "        [-7.09169214e-06]]), 'W3': array([[-0.00453181,  0.00474864, -0.00231886]]), 'b3': array([[0.00323145]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_p_with_for(parametres, grads, learning_rate = 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_param_with_for(parametres, grads, learning_rate=1.2):\n",
    "    \n",
    "#     parametres = {}\n",
    "#     print(\"parametres\", parametres )\n",
    "    \n",
    "#     p =len(parametres) \n",
    "#     print(\"p\", p)\n",
    "#     parametres[\"W1\"] = grads[\"dW\" + str(1)]\n",
    "#     print(parametres)\n",
    "    \n",
    "#     for i in reversed(range(1, p +1)):\n",
    "#         print(\"EST CE QUE J'EXISTE???? :()\")\n",
    "#         dW = grads[\"dW\" + str(i)]\n",
    "#         db = grads[\"db\" + str(i)]\n",
    "#         W = parametres[\"W\" + str(i)]- learning_rate * dW\n",
    "        \n",
    "#         b = parametres[\"b\" + str(i)]- learning_rate * db\n",
    "        \n",
    "#     return parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametres = update_param_with_for(parametres, grads, learning_rate=1.1)\n",
    "# parametres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-449a48dc482c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-449a48dc482c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def neural_network_model(X, Y, nombre_iteration = 1000, l print_cost = False):\u001b[0m\n\u001b[0m                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def neural_network_model(X, Y, nombre_iteration = 1000, l print_cost = False):\n",
    "    \n",
    "    n_x = (X, Y)[0]\n",
    "    n_y = (X, Y)[1]*1\n",
    "   \n",
    "    parametres = initialisation_param(architecture)\n",
    "    W1 = parametres[\"W1\"]\n",
    "    W2 = parametres[\"W2\"]\n",
    "    w3 = parametres[\"W3\"]\n",
    "    b1 = parametres[\"b1\"]\n",
    "    b2 = parametres[\"b2\"]\n",
    "    b3 = parametres[\"b3\"]\n",
    "    \n",
    "    for i in range(0, nombre_iteration):\n",
    "        A3, caches = forward(X, parametres)\n",
    "        cost = cost(A3, Y,parametres)\n",
    "        grads = backward_pro(parametres, caches, X, Y)\n",
    "        parametres = update_parametres(parametres, grads, learning_rate=1.2)\n",
    "        \n",
    "        if print_cost and i% 1000 == 0:\n",
    "            print(\"cost after iteration %i : %f\" %(i,cost))\n",
    "    \n",
    "    return parametres\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_model(X, Y, nombre_iteration = 1000, print_cost = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = len(parametres)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in reversed(range(1, p +1)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, Y)[1]*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
